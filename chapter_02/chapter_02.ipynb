{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I went there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemme', 'that']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "from spacy.symbols import ORTH \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "doc = nlp(\"lemme that\") \n",
    "print([w.text for w in doc]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lem', 'me', 'that']\n"
     ]
    }
   ],
   "source": [
    "special_case = [{ORTH: \"lem\"}, {ORTH: \"me\"}] \n",
    "nlp.tokenizer.add_special_case(\"lemme\", special_case) \n",
    "print([w.text for w in nlp(\"lemme that\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lem', 'me', '!']\n"
     ]
    }
   ],
   "source": [
    "print([w.text for w in nlp(\"lemme!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['...lemme...?']\n"
     ]
    }
   ],
   "source": [
    "nlp.tokenizer.add_special_case(\"...lemme...?\", [{\"ORTH\": \"...lemme...?\"}])\n",
    "print([w.text for w in nlp(\"...lemme...?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let \t SPECIAL-1\n",
      "'s \t SPECIAL-2\n",
      "go \t TOKEN\n",
      "! \t SUFFIX\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "text = \"Let's go!\" \n",
    "doc = nlp(text) \n",
    "\n",
    "tok_exp = nlp.tokenizer.explain(text) \n",
    "for t in tok_exp: \n",
    "    print(t[1], \"\\t\", t[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I flied to N.Y yesterday.\n",
      "It was around 5 pm.\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"I flied to N.Y yesterday. It was around 5 pm.\"\n",
    "doc = nlp(text) \n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "went go\n",
      "there there\n",
      "for for\n",
      "working work\n",
      "and and\n",
      "worked work\n",
      "for for\n",
      "3 3\n",
      "years year\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "doc = nlp(\"I went there for working and worked for 3 years.\") \n",
    "for token in doc: \n",
    "    print(token.text, token.lemma_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "am be\n",
      "flying fly\n",
      "to to\n",
      "Angeltown Los Angeles\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"TEXT\": \"Angeltown\"}]], {\"LEMMA\": \"Los Angeles\"})\n",
    "\n",
    "doc = nlp(\"I am flying to Angeltown\")\n",
    "for token in doc: \n",
    "    print(token.text, token.lemma_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like cats.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I like cats.\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "like\n",
      "cats\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n"
     ]
    }
   ],
   "source": [
    "print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[This is a sentence., This is the second sentence]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is a sentence. This is the second sentence\")\n",
    "sentences = list(doc.sents)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New York, Ashley)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I flied to New York with Ashley.\")\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sweet brown fox, the fence]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Sweet brown fox jumped over the fence.\")\n",
    "print(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": [
    "print(doc.lang_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ents': [],\n",
      " 'sents': [{'end': 2, 'start': 0}],\n",
      " 'text': 'Hi',\n",
      " 'tokens': [{'dep': 'ROOT',\n",
      "             'end': 2,\n",
      "             'head': 0,\n",
      "             'id': 0,\n",
      "             'lemma': 'hi',\n",
      "             'morph': '',\n",
      "             'pos': 'INTJ',\n",
      "             'start': 0,\n",
      "             'tag': 'UH'}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "doc = nlp(\"Hi\")\n",
    "json_doc = doc.to_json()\n",
    "pprint(json_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.text\n",
    "token.text_with_ws\n",
    "token.i\n",
    "token.idx\n",
    "token.doc\n",
    "token.sent\n",
    "token.is_sent_start\n",
    "token.ent_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hello Madam!\")\n",
    "print(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello \n",
      "!\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].text_with_ws)\n",
    "print(doc[2].text_with_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].text_with_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].text_with_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "token = doc[2]\n",
    "print(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].idx)\n",
    "print(doc[1].idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Madam!\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print(token.doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Madam!\n"
     ]
    }
   ],
   "source": [
    "token = doc[1]\n",
    "print(token.sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"He entered the room. Then he nodded.\") \n",
    "print(doc[0].is_sent_start)\n",
    "print(doc[5].is_sent_start)\n",
    "print(doc[6].is_sent_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I went there.\")\n",
    "print(doc[1].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Brazilian, Beijing)\n",
      "\n",
      "NORP Nationalities or religious or political groups\n",
      "\n",
      "\n",
      "GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The Brazilian president visited Beijing\")\n",
    "print(doc.ents)\n",
    "print(doc[0].ent_type_)\n",
    "print(doc[1].ent_type_, spacy.explain(doc[1].ent_type_))\n",
    "print(doc[2].ent_type_)\n",
    "print(doc[3].ent_type_)\n",
    "print(doc[4].ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coldly calculated\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"All my moves are coldly calculated.\") \n",
    "print(doc[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated.\n",
      "coldly calculated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"All my moves are coldly calculated.\") \n",
    "print(doc[5:]) # end index empty means rest of the string calculated. \n",
    "print(doc[4:-1]) # minus indexes are supported "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little piece of Brazil\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Recife has a thousand charms, it's a little piece of Brazil.\") \n",
    "print(doc.char_span(37, 59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there\n",
      "after\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"You went there after you saw me\")\n",
    "span = doc[2:4] \n",
    "for token in span: \n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Hi Lorena!!\") \n",
    "span = doc[:2] \n",
    "len(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there after you saw\n",
      "after you\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"You went there after you saw me\") \n",
    "span = doc[2:6] \n",
    "print(span)\n",
    "print(span[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You went there after you saw me\n",
      "You went there after you saw me\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"You went there after you saw me\")\n",
    "span = doc[2:6] \n",
    "print(span.doc)\n",
    "print(span.sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "9\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"You went there after you saw me\")\n",
    "span = doc[2:6]\n",
    "print(span.start) # the index of the first token of the Span\n",
    "print(span.end)\n",
    "print(span.start_char) # the start offset of the Span at character level\n",
    "print(span.end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"You went there after you saw me\")\n",
    "span = doc[2:6]\n",
    "small_doc = span.as_doc()\n",
    "print(type(small_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hello, hi!\") \n",
    "print(doc[0].lower_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Cat and Cat123\") \n",
    "print(doc[0].is_alpha)\n",
    "print(doc[2].is_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"UR7 and Várzea\")\n",
    "print(doc[0].is_ascii)\n",
    "print(doc[2].is_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Cat Cat123 123\")\n",
    "print(doc[0].is_digit)\n",
    "print(doc[1].is_digit)\n",
    "print(doc[2].is_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"You, him and Sally\")\n",
    "print(doc[1])\n",
    "print(doc[1].is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "True\n",
      "]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"( [ He said yes. ] )\") \n",
    "print(doc[0])\n",
    "print(doc[0].is_left_punct)\n",
    "print(doc[-2])\n",
    "print(doc[-2].is_right_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "True\n",
      "hundred\n",
      "True\n",
      "hello@hello.com\n",
      "True\n",
      "https://nicewebsite.com\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I emailed you at least 100 times\") \n",
    "print(doc[-2])\n",
    "print(doc[-2].like_num)\n",
    "\n",
    "doc = nlp(\"I emailed you at least hundred times\") \n",
    "print(doc[-2])\n",
    "print(doc[-2].like_num)\n",
    "\n",
    "doc = nlp(\"His email is hello@hello.com and his website is https://nicewebsite.com\") \n",
    "print(doc[3])\n",
    "print(doc[3].like_email)\n",
    "print(doc[8])\n",
    "print(doc[8].like_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girl Xxxx\n",
      "called xxxx\n",
      "Kathy Xxxxx\n",
      "has xxx\n",
      "a x\n",
      "nickname xxxx\n",
      "Cat123 Xxxddd\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Girl called Kathy has a nickname Cat123.\") \n",
    "for token in doc: \n",
    "    print(token.text, token.shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I True\n",
      "visited True\n",
      "Jenny True\n",
      "at True\n",
      "Mynks True\n",
      "Resort True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I visited Jenny at Mynks Resort\")\n",
    "for token in doc: \n",
    "    print(token, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One True\n",
      "step False\n",
      "forward False\n",
      ", False\n",
      "and True\n",
      "you True\n",
      "'re True\n",
      "no True\n",
      "longer False\n",
      "in True\n",
      "the True\n",
      "same True\n",
      "place False\n",
      ". False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"One step forward, and you're no longer in the same place.\")\n",
    "for token in doc: \n",
    "    print(token, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
